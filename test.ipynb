{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if 3d_2d result is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D and 3D points correspond.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "points_2d = np.loadtxt(\"./dataset/2d_array/0.txt\")\n",
    "points_3d = np.loadtxt(\"./dataset/3d_array/0.txt\")\n",
    "\n",
    "#with open(\"./dataset/2d_array/0.pkl\", \"rb\") as f:\n",
    "#    points_2d = pickle.load(f)\n",
    "\n",
    "#with open(\"./dataset/3d_array/0.pkl\", \"rb\") as f:\n",
    "#    points_3d = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('./dataset/intrinsics.json') as f:\n",
    "    intrinsics = json.load(f)\n",
    "f_x = intrinsics['fx']\n",
    "f_y = intrinsics['fy']\n",
    "c_x = intrinsics['ppx']\n",
    "c_y = intrinsics['ppy']\n",
    "\n",
    "\n",
    "intrinsics_matrix = np.array([[f_x, 0, c_x],\n",
    "                              [0, f_y, c_y],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "# Define the initial guess for the camera extrinsic parameters\n",
    "R = np.eye(3)\n",
    "t = np.zeros((3, 1))\n",
    "\n",
    "# Run the PnP algorithm\n",
    "success, R_est, t_est = cv2.solvePnP(points_3d, points_2d, intrinsics_matrix, None, flags=cv2.SOLVEPNP_ITERATIVE, rvec=R, tvec=t)\n",
    "\n",
    "# Check if the PnP algorithm was successful\n",
    "if not success:\n",
    "    print('PnP algorithm failed to converge.')\n",
    "else:\n",
    "    # Project the 3D points onto the image plane using the estimated camera parameters\n",
    "    projected_points, _ = cv2.projectPoints(points_3d, R_est, t_est, intrinsics_matrix, None)\n",
    "\n",
    "    # Calculate the reprojection error\n",
    "    error = cv2.norm(points_2d, projected_points.squeeze(), cv2.NORM_L2) / np.sqrt(points_2d.shape[0])\n",
    "\n",
    "    # Check if the reprojection error is below a threshold\n",
    "    if error > 1:\n",
    "        print('2D and 3D points do not correspond.')\n",
    "    else:\n",
    "        print('2D and 3D points correspond.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5076, 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "with open(\"./dataset/2d_array/0.pkl\", \"rb\") as f:\n",
    "    points_2d = pickle.load(f)\n",
    "\n",
    "print(points_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m# Convert the combined point cloud to an Open3D point cloud object\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pcd \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mPointCloud()\n\u001b[1;32m---> 27\u001b[0m pcd\u001b[39m.\u001b[39mpoints \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39;49mutility\u001b[39m.\u001b[39;49mVector3dVector(combined_point_cloud)\n\u001b[0;32m     29\u001b[0m \u001b[39m# Display the point cloud\u001b[39;00m\n\u001b[0;32m     30\u001b[0m o3d\u001b[39m.\u001b[39mvisualization\u001b[39m.\u001b[39mdraw_geometries([pcd])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Specify the directory containing the .pkl files\n",
    "directory = './point_cloud/'\n",
    "\n",
    "# Create an empty list to store the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "# Iterate over all .pkl files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pkl'):\n",
    "        # Load the point cloud from the file\n",
    "        with open(os.path.join(directory, filename), 'rb') as f:\n",
    "            point_cloud = pickle.load(f)\n",
    "        \n",
    "        # Append the point cloud to the list\n",
    "        point_clouds.append(point_cloud)\n",
    "\n",
    "# Concatenate all point clouds into a single point cloud\n",
    "combined_point_cloud = np.concatenate(point_clouds, axis=0)\n",
    "\n",
    "# Convert the combined point cloud to an Open3D point cloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(combined_point_cloud)\n",
    "\n",
    "# Display the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import open3d as o3d\n",
    "\n",
    "# Load the pkl file containing the point cloud\n",
    "with open('point_cloud_world1.pkl', 'rb') as f:\n",
    "    point_cloud = pickle.load(f)\n",
    "\n",
    "# Create an Open3D point cloud object from the numpy array\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show rgb, mask and bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the RGB image\n",
    "img = cv2.imread('./rgb/color_0.png')\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the lower and upper bounds of the orange color in HSV\n",
    "lower_orange = np.array([8, 50, 50])\n",
    "upper_orange = np.array([11, 255, 255])\n",
    "\n",
    "# Create a mask using the color threshold\n",
    "mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
    "mask = np.where(mask == 255, 1, mask)\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the largest contour\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Draw a bounding box around the largest contour\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "result = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Create a new mask that is the same size as the original image and fill it with zeros\n",
    "new_mask = np.zeros_like(mask)\n",
    "\n",
    "# Set the values inside the bounding box to be the same as the values in the original mask\n",
    "new_mask[y:y+h, x:x+w] = mask[y:y+h, x:x+w]\n",
    "\n",
    "mask = np.zeros((new_mask.shape[0],new_mask.shape[1],3), dtype=int)\n",
    "\n",
    "mask[:,:,0] = new_mask\n",
    "mask[:,:,1] = new_mask\n",
    "mask[:,:,2] = new_mask\n",
    "\n",
    "# Apply the new mask to the original image to extract the orange wood cube within the bounding box\n",
    "\n",
    "# Display the result\n",
    "#cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Mask', new_mask)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.imwrite(f\"./mask/mask_{0}.png\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show where is the non-zero pixel in mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"./mask/mask_0.png\")\n",
    "b, g, r = cv2.split(img)\n",
    "# Find the coordinates of pixels that have a different value between the channels\n",
    "diff_pixels = np.where((r != 0))\n",
    "\n",
    "# Print the coordinates of the different pixels\n",
    "for i in range(len(diff_pixels[0])):\n",
    "    print(\"Coordinate ({}, {}) has different pixel values between channels\".format(diff_pixels[0][i], diff_pixels[1][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show mask only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = Image.open(\"./mask/mask_59.png\")\n",
    "img_array = np.array(img)\n",
    "img_array[img_array == 1] = 255\n",
    "img = Image.fromarray(img_array)\n",
    "img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the image using OpenCV\n",
    "cv2.imshow('Image', img_cv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate .pcd point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.88513871e-03  1.90047300e-03  9.99974491e-01 -1.84220698e-03]\n",
      " [-5.62283386e-01  8.26941415e-01  2.29987795e-03 -6.95060990e-05]\n",
      " [-8.26915950e-01 -5.62284878e-01  6.76221074e-03  9.99643111e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "(480, 640)\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def create_point_cloud_from_rgbd_image(color, depth, intrinsic, extrinsic, mask):\n",
    "    color = color * mask[:, :, np.newaxis]\n",
    "    depth = depth * mask\n",
    "    print(color)\n",
    "    print(depth.shape)\n",
    "\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        o3d.geometry.Image(color),\n",
    "        o3d.geometry.Image(depth),\n",
    "        depth_scale=1000,\n",
    "        depth_trunc=1.0,\n",
    "        convert_rgb_to_intensity=False\n",
    "    )\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image,\n",
    "        intrinsic,\n",
    "        extrinsic\n",
    "    )\n",
    "    return pcd\n",
    "\n",
    "# Load the color and depth images\n",
    "color = o3d.io.read_image(\"./dataset/rgb_0.png\")\n",
    "depth = o3d.io.read_image(\"./dataset/depth_0.png\")\n",
    "mask = o3d.io.read_image(\"./dataset/mask_0.png\")\n",
    "mask = np.asarray(mask)\n",
    "#mask[:] = 1\n",
    "mask = mask.astype(bool)\n",
    "\n",
    "with open('./dataset/intrinsics.json') as f:\n",
    "    intrinsics = json.load(f)\n",
    "f_x = intrinsics['fx']\n",
    "f_y = intrinsics['fy']\n",
    "c_x = intrinsics['ppx']\n",
    "c_y = intrinsics['ppy']\n",
    "\n",
    "\n",
    "# Load the camera intrinsic parameters\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "    width=1280,\n",
    "    height=720,\n",
    "    fx=f_x,\n",
    "    fy=f_y,\n",
    "    cx=c_x,\n",
    "    cy=c_y\n",
    ")\n",
    "\n",
    "pose = np.load('./dataset/pose_0.npy')\n",
    "print(pose)\n",
    "R = pose[0:3, 0:3]\n",
    "T = pose[0:3, 3]\n",
    "extrinsic = np.eye(4)\n",
    "extrinsic[:3, :3] = R\n",
    "extrinsic[:3, 3] = T\n",
    "\n",
    "# Create the point cloud\n",
    "pcd = create_point_cloud_from_rgbd_image(color, depth, intrinsic, extrinsic, mask)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "o3d.io.write_point_cloud(\"cube_point_cloud.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Load the PLY file\n",
    "ply_file = o3d.io.read_point_cloud('cube_point_cloud.ply')\n",
    "points = np.asarray(ply_file.points)\n",
    "\n",
    "# Load the camera intrinsic and extrinsic parameters\n",
    "intrinsics_matrix = np.array([[f_x, 0, c_x],\n",
    "                              [0, f_y, c_y],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "print(T.shape)\n",
    "extrinsics_matrix = np.hstack((R, np.expand_dims(T, -1)))\n",
    "\n",
    "# Initialize a dictionary to store the correspondences\n",
    "correspondences = {}\n",
    "\n",
    "# Iterate over all 3D points and establish correspondences\n",
    "for point_3d in points:\n",
    "    # Transform the 3D point to camera coordinates\n",
    "    point_3d_hom = np.hstack((point_3d, 1))\n",
    "    point_camera_hom = extrinsics_matrix @ point_3d_hom\n",
    "    point_camera = point_camera_hom[:3]\n",
    "\n",
    "    # Project the 3D point onto the camera image plane\n",
    "    point_hom = intrinsics_matrix @ point_camera\n",
    "    point_2d_hom = point_hom / point_hom[2]\n",
    "    point_2d = point_2d_hom[:2]\n",
    "\n",
    "    # Store the correspondence between the 3D point and the corresponding 2D point\n",
    "    correspondences[tuple(point_3d)] = tuple(point_2d)\n",
    "\n",
    "# Print the correspondences\n",
    "for point_3d, point_2d in correspondences.items():\n",
    "    print(f'3D point: {point_3d} | 2D point: {point_2d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D and 3D points correspond.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "points_2d = []\n",
    "points_3d = []\n",
    "# Define the 2D and 3D points\n",
    "for point_3d, point_2d in correspondences.items():\n",
    "    points_2d.append(point_2d)\n",
    "    points_3d.append(point_3d)\n",
    "\n",
    "points_2d = np.array(points_2d)\n",
    "points_3d = np.array(points_3d)\n",
    "\n",
    "with open('./dataset/intrinsics.json') as f:\n",
    "    intrinsics = json.load(f)\n",
    "f_x = intrinsics['fx']\n",
    "f_y = intrinsics['fy']\n",
    "c_x = intrinsics['ppx']\n",
    "c_y = intrinsics['ppy']\n",
    "\n",
    "\n",
    "intrinsics_matrix = np.array([[f_x, 0, c_x],\n",
    "                              [0, f_y, c_y],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "# Define the initial guess for the camera extrinsic parameters\n",
    "R = np.eye(3)\n",
    "t = np.zeros((3, 1))\n",
    "\n",
    "# Run the PnP algorithm\n",
    "success, R_est, t_est = cv2.solvePnP(points_3d, points_2d, intrinsics_matrix, None, flags=cv2.SOLVEPNP_ITERATIVE, rvec=R, tvec=t)\n",
    "\n",
    "# Check if the PnP algorithm was successful\n",
    "if not success:\n",
    "    print('PnP algorithm failed to converge.')\n",
    "else:\n",
    "    # Project the 3D points onto the image plane using the estimated camera parameters\n",
    "    projected_points, _ = cv2.projectPoints(points_3d, R_est, t_est, intrinsics_matrix, None)\n",
    "\n",
    "    # Calculate the reprojection error\n",
    "    error = cv2.norm(points_2d, projected_points.squeeze(), cv2.NORM_L2) / np.sqrt(points_2d.shape[0])\n",
    "\n",
    "    # Check if the reprojection error is below a threshold\n",
    "    if error > 1:\n",
    "        print('2D and 3D points do not correspond.')\n",
    "    else:\n",
    "        print('2D and 3D points correspond.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert mask image to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = o3d.io.read_image(\"./mask/mask_0.png\")\n",
    "mask = np.asarray(mask)\n",
    "mask = mask[:,:,0]\n",
    "mask = np.asarray(mask)\n",
    "np.savetxt(\"mask.txt\", mask)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyk4a as k4a\n",
    "import json\n",
    "\n",
    "config = k4a.Config(\n",
    "    color_resolution=k4a.ColorResolution.RES_720P,\n",
    "    depth_mode=k4a.DepthMode.WFOV_2X2BINNED,\n",
    "    synchronized_images_only=True,\n",
    "    camera_fps=k4a.FPS.FPS_30,\n",
    ")\n",
    "kinect = k4a.PyK4A(config)\n",
    "# Initialize the Azure Kinect device\n",
    "kinect.start()\n",
    "\n",
    "# Get the calibration information for the device\n",
    "calibration = kinect.calibration\n",
    "capture = kinect.get_capture(-1)\n",
    "\n",
    "# Get the extrinsic matrix between the color and depth cameras\n",
    "extrinsics = calibration.get_extrinsic_parameters(k4a.calibration.CalibrationType.DEPTH,k4a.calibration.CalibrationType.COLOR)\n",
    "# Save the extrinsic matrix to a file\n",
    "\n",
    "rotation = extrinsics[0]\n",
    "translation = extrinsics[1]\n",
    "\n",
    "# Convert the matrices to lists for JSON serialization\n",
    "rotation_list = rotation.flatten().tolist()\n",
    "translation_list = translation.tolist()\n",
    "\n",
    "# Create a dictionary to hold the extrinsics information\n",
    "extrinsics_dict = {\n",
    "    \"rotation\": rotation_list,\n",
    "    \"translation\": translation_list\n",
    "}\n",
    "\n",
    "# Save the extrinsics to a JSON file\n",
    "with open(\"./extrinsic/extrinsics_d_c.json\", \"w\") as f:\n",
    "    json.dump(extrinsics_dict, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return 2d mask and 3d point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load RGB image and depth map\n",
    "rgb_image = cv2.imread('./rgb/color_0.png')\n",
    "depth_map = cv2.imread('./depth_map/depth_map_0.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Load intrinsic matrix\n",
    "intrinsic_matrix = np.loadtxt('./intrinsic_depth/intrinsicc_0.txt')\n",
    "\n",
    "# Load mask image\n",
    "mask = cv2.imread('./mask/mask_0.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize list to store 3D coordinates of points\n",
    "points = []\n",
    "masks = []\n",
    "\n",
    "# Loop over each pixel in the RGB image\n",
    "for i in range(rgb_image.shape[0]):\n",
    "    for j in range(rgb_image.shape[1]):\n",
    "        # Check if the pixel is masked or not\n",
    "        if mask[i, j]:\n",
    "            # Convert pixel coordinate and depth value to 3D point\n",
    "            homogeneous_pixel = np.array([j, i, 1])\n",
    "            homogeneous_point = np.append(np.dot(np.linalg.inv(intrinsic_matrix), homogeneous_pixel), 1)\n",
    "            depth = depth_map[i, j] / 1000.0  # convert from millimeters to meters\n",
    "            point = homogeneous_point * depth\n",
    "            points.append(point[:3])\n",
    "            masks.append([j,i])\n",
    "\n",
    "# Convert list to numpy array\n",
    "point_cloud = np.array(points)\n",
    "masks = np.array(masks)\n",
    "# Save point cloud to disk\n",
    "np.savetxt('./point_cloud.txt', point_cloud)\n",
    "np.savetxt('./mask.txt', masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmask.txt\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n\u001b[1;32m---> 13\u001b[0m         x, y \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mround\u001b[39m, \u001b[39mfloat\u001b[39;49m(line\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49msplit()))\n\u001b[0;32m     14\u001b[0m         mask[y, x] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Create a figure with two subplots\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = plt.imread('./rgb/color_0.png')\n",
    "\n",
    "# Create an empty mask array\n",
    "mask = np.zeros_like(image)\n",
    "\n",
    "# Load the mask coordinates from text file\n",
    "with open('mask.txt') as f:\n",
    "    for line in f:\n",
    "        x, y = map(round, line.strip().split())\n",
    "        mask[y, x] = 1\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# Display the image on the left subplot\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image')\n",
    "\n",
    "# Display the mask on the right subplot\n",
    "ax2.imshow(mask, cmap='gray')\n",
    "ax2.set_title('Mask')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4254ad4feefaf1fe4b7b43b6319962596181cba2564984ad5012037c11223dbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
